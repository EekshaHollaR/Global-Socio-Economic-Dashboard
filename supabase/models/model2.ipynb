{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5225,
     "status": "ok",
     "timestamp": 1761669035198,
     "user": {
      "displayName": "Swaroop Tandle",
      "userId": "04403577212311715821"
     },
     "user_tz": -330
    },
    "id": "HDzOHEeamNVC",
    "outputId": "2c711222-b96e-4c2d-cc79-6d12e7bd872a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Crisis labels (0/1) added successfully!\n",
      "Crisis_Label\n",
      "0    3432\n",
      "1    1194\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_excel(r\"C:\\Users\\Eeksha\\Desktop\\GSECD-final-project1.0\\version2\\civic-data-forge-main\\supabase\\data\\dataset2.xlsx\")\n",
    "\n",
    "# ----------------------------\n",
    "# Define crisis conditions with research-backed thresholds\n",
    "# ----------------------------\n",
    "conditions = pd.DataFrame({\n",
    "    \"low_yield\": df[\"Cereal yield (kg per hectare)\"] < 1000,                # global concern minimum\n",
    "    \"high_imports\": df[\"Food imports (% of merchandise imports)\"] > 15,     # import stress threshold\n",
    "    \"low_production\": df[\"Food production index (2014-2016 = 100)\"] < 100,  # early warning\n",
    "    \"low_gdp_growth\": df[\"GDP growth (annual %)\"] < 2,                      # economic stress\n",
    "    \"low_gdp_per_capita\": df[\"GDP per capita (current US$)\"] < 784,         # $2.15/day poverty line\n",
    "    \"high_inflation\": df[\"Inflation, consumer prices (annual %)\"] > 10,     # risk threshold\n",
    "    \"high_population_growth\": df[\"Population growth (annual %)\"] > 2.5       # food system pressure\n",
    "})\n",
    "\n",
    "# ----------------------------\n",
    "# Count how many conditions are True per row\n",
    "# ----------------------------\n",
    "df[\"Crisis_Count\"] = conditions.sum(axis=1)\n",
    "\n",
    "# ----------------------------\n",
    "# Label: Crisis (1) if 3 or more risk signals, else No Crisis (0)\n",
    "# ----------------------------\n",
    "df[\"Crisis_Label\"] = (df[\"Crisis_Count\"] >= 3).astype(int)\n",
    "\n",
    "# ----------------------------\n",
    "# Save updated dataset (optional)\n",
    "# ----------------------------\n",
    "df.to_csv(\"food_crisis_dataset_labeled.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Crisis labels (0/1) added successfully!\")\n",
    "print(df[\"Crisis_Label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6374,
     "status": "ok",
     "timestamp": 1761670044547,
     "user": {
      "displayName": "Swaroop Tandle",
      "userId": "04403577212311715821"
     },
     "user_tz": -330
    },
    "id": "FAqz17YDqLQC",
    "outputId": "19613fe5-58e5-4c06-87a4-1d9def69c6b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eeksha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Model Accuracy: 96.87%\n",
      "\n",
      "âœ… ROC-AUC Score: 0.997\n",
      "\n",
      "\n",
      "ðŸ”¥ High-Risk Countries (â‰¥80% Crisis Probability)\n",
      "\n",
      "ðŸš¨ Botswana â€” Crisis Probability: 95.00%\n",
      "   Food imports (% of merchandise imports)       Contribution: +0.193 | Value: 16.21\n",
      "   Cereal yield (kg per hectare)                 Contribution: +0.179 | Value: 468.90\n",
      "   GDP growth (annual %)                         Contribution: +0.119 | Value: -2.99\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Burundi â€” Crisis Probability: 91.00%\n",
      "   GDP per capita (current US$)                  Contribution: +0.283 | Value: 153.93\n",
      "   Inflation, consumer prices (annual %)         Contribution: +0.147 | Value: 20.21\n",
      "   Population growth (annual %)                  Contribution: +0.129 | Value: 2.58\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Cabo Verde â€” Crisis Probability: 97.50%\n",
      "   Cereal yield (kg per hectare)                 Contribution: +0.351 | Value: 23.00\n",
      "   Food imports (% of merchandise imports)       Contribution: +0.185 | Value: 20.21\n",
      "   Food production index (2014-2016 = 100)       Contribution: +0.114 | Value: 74.78\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Central African Republic â€” Crisis Probability: 96.00%\n",
      "   GDP per capita (current US$)                  Contribution: +0.174 | Value: 516.17\n",
      "   Cereal yield (kg per hectare)                 Contribution: +0.162 | Value: 878.10\n",
      "   Food production index (2014-2016 = 100)       Contribution: -0.123 | Value: 147.99\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Cuba â€” Crisis Probability: 99.50%\n",
      "   Food imports (% of merchandise imports)       Contribution: +0.304 | Value: 25.21\n",
      "   GDP growth (annual %)                         Contribution: +0.188 | Value: -1.93\n",
      "   Food production index (2014-2016 = 100)       Contribution: +0.161 | Value: 71.39\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Gambia, The â€” Crisis Probability: 88.00%\n",
      "   Cereal yield (kg per hectare)                 Contribution: +0.227 | Value: 800.70\n",
      "   Food imports (% of merchandise imports)       Contribution: -0.157 | Value: 7.31\n",
      "   Inflation, consumer prices (annual %)         Contribution: +0.147 | Value: 11.56\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Grenada â€” Crisis Probability: 92.00%\n",
      "   Cereal yield (kg per hectare)                 Contribution: +0.295 | Value: 998.80\n",
      "   Food imports (% of merchandise imports)       Contribution: +0.190 | Value: 24.18\n",
      "   Food production index (2014-2016 = 100)       Contribution: +0.112 | Value: 86.71\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Haiti â€” Crisis Probability: 98.00%\n",
      "   Inflation, consumer prices (annual %)         Contribution: +0.203 | Value: 26.95\n",
      "   GDP growth (annual %)                         Contribution: +0.145 | Value: -4.17\n",
      "   Cereal yield (kg per hectare)                 Contribution: +0.125 | Value: 1062.60\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Iran, Islamic Rep. â€” Crisis Probability: 94.50%\n",
      "   Inflation, consumer prices (annual %)         Contribution: +0.278 | Value: 32.46\n",
      "   Food imports (% of merchandise imports)       Contribution: +0.266 | Value: 29.46\n",
      "   Food production index (2014-2016 = 100)       Contribution: +0.111 | Value: 83.89\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Lebanon â€” Crisis Probability: 92.00%\n",
      "   Inflation, consumer prices (annual %)         Contribution: +0.324 | Value: 45.24\n",
      "   Food imports (% of merchandise imports)       Contribution: +0.187 | Value: 16.26\n",
      "   GDP growth (annual %)                         Contribution: +0.160 | Value: -0.76\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Lesotho â€” Crisis Probability: 88.50%\n",
      "   Cereal yield (kg per hectare)                 Contribution: +0.296 | Value: 804.10\n",
      "   Food imports (% of merchandise imports)       Contribution: +0.167 | Value: 22.51\n",
      "   GDP growth (annual %)                         Contribution: -0.078 | Value: 2.76\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Malawi â€” Crisis Probability: 85.50%\n",
      "   GDP per capita (current US$)                  Contribution: +0.285 | Value: 508.37\n",
      "   Inflation, consumer prices (annual %)         Contribution: +0.144 | Value: 32.18\n",
      "   Population growth (annual %)                  Contribution: +0.139 | Value: 2.58\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Mozambique â€” Crisis Probability: 99.00%\n",
      "   GDP per capita (current US$)                  Contribution: +0.183 | Value: 647.29\n",
      "   Cereal yield (kg per hectare)                 Contribution: +0.182 | Value: 737.70\n",
      "   Population growth (annual %)                  Contribution: +0.118 | Value: 2.92\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Niger â€” Crisis Probability: 95.00%\n",
      "   Cereal yield (kg per hectare)                 Contribution: +0.212 | Value: 488.70\n",
      "   GDP per capita (current US$)                  Contribution: +0.192 | Value: 722.75\n",
      "   Population growth (annual %)                  Contribution: +0.136 | Value: 3.28\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Palau â€” Crisis Probability: 94.00%\n",
      "   Food imports (% of merchandise imports)       Contribution: +0.248 | Value: 22.96\n",
      "   GDP growth (annual %)                         Contribution: +0.147 | Value: 1.88\n",
      "   Food production index (2014-2016 = 100)       Contribution: +0.139 | Value: 95.25\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Sudan â€” Crisis Probability: 95.50%\n",
      "   Cereal yield (kg per hectare)                 Contribution: +0.179 | Value: 449.10\n",
      "   Inflation, consumer prices (annual %)         Contribution: +0.155 | Value: 138.81\n",
      "   Food imports (% of merchandise imports)       Contribution: +0.153 | Value: 29.91\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Suriname â€” Crisis Probability: 85.50%\n",
      "   Inflation, consumer prices (annual %)         Contribution: +0.279 | Value: 16.23\n",
      "   Food imports (% of merchandise imports)       Contribution: +0.205 | Value: 15.50\n",
      "   Food production index (2014-2016 = 100)       Contribution: +0.129 | Value: 87.89\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Syrian Arab Republic â€” Crisis Probability: 98.50%\n",
      "   Food imports (% of merchandise imports)       Contribution: +0.146 | Value: 21.04\n",
      "   Inflation, consumer prices (annual %)         Contribution: +0.104 | Value: 13.42\n",
      "   Population growth (annual %)                  Contribution: +0.101 | Value: 4.47\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Trinidad and Tobago â€” Crisis Probability: 87.50%\n",
      "   Food imports (% of merchandise imports)       Contribution: +0.240 | Value: 16.44\n",
      "   GDP growth (annual %)                         Contribution: +0.153 | Value: 1.65\n",
      "   Food production index (2014-2016 = 100)       Contribution: +0.136 | Value: 93.08\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Vanuatu â€” Crisis Probability: 94.00%\n",
      "   Cereal yield (kg per hectare)                 Contribution: +0.214 | Value: 633.20\n",
      "   Food imports (% of merchandise imports)       Contribution: +0.154 | Value: 24.96\n",
      "   Food production index (2014-2016 = 100)       Contribution: +0.094 | Value: 82.96\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Venezuela, RB â€” Crisis Probability: 100.00%\n",
      "   Food imports (% of merchandise imports)       Contribution: +0.212 | Value: 18.41\n",
      "   Inflation, consumer prices (annual %)         Contribution: +0.196 | Value: 254.95\n",
      "   GDP growth (annual %)                         Contribution: +0.147 | Value: -3.89\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Yemen, Rep. â€” Crisis Probability: 100.00%\n",
      "   GDP per capita (current US$)                  Contribution: +0.158 | Value: 633.89\n",
      "   Cereal yield (kg per hectare)                 Contribution: +0.158 | Value: 801.10\n",
      "   Population growth (annual %)                  Contribution: +0.115 | Value: 2.98\n",
      "----------------------------------------------------------------------\n",
      "ðŸš¨ Zimbabwe â€” Crisis Probability: 81.50%\n",
      "   Cereal yield (kg per hectare)                 Contribution: +0.238 | Value: 743.90\n",
      "   Inflation, consumer prices (annual %)         Contribution: +0.193 | Value: 104.71\n",
      "   Food imports (% of merchandise imports)       Contribution: +0.159 | Value: 18.96\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ðŸ“‚ Saved future-year predictions to: food_future_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# food_crisis_workflow.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ===============================\n",
    "# 1. Load dataset\n",
    "# ===============================\n",
    "# Update path if needed\n",
    "data = pd.read_csv(r\"C:\\Users\\Eeksha\\Desktop\\GSECD-final-project1.0\\version2\\civic-data-forge-main\\supabase\\models\\food_crisis_dataset_labeled.csv\")\n",
    "\n",
    "# Ensure Year column is int (same idea as your economic code's Date)\n",
    "if \"Year\" in data.columns:\n",
    "    data[\"Year\"] = data[\"Year\"].astype(int)\n",
    "else:\n",
    "    raise KeyError(\"Expected 'Year' column in dataset.\")\n",
    "\n",
    "# ===============================\n",
    "# 2. Features and target\n",
    "# ===============================\n",
    "# Drop the label + identifying cols (adjust names if differ)\n",
    "drop_cols = [\"Crisis_Label\", \"Country Name\", \"Year\", \"Country Code\", \"Crisis_Count\"]\n",
    "X = data.drop(columns=[c for c in drop_cols if c in data.columns], errors=\"ignore\")\n",
    "y = data[\"Crisis_Label\"]\n",
    "country_year = data[[\"Country Name\", \"Year\"]]\n",
    "\n",
    "# (Optional) keep the feature order consistent (you can adjust list if necessary)\n",
    "# expected_features = [...]\n",
    "# X = X[expected_features]\n",
    "\n",
    "# ===============================\n",
    "# 3. Split dataset (train/test)\n",
    "# ===============================\n",
    "X_train, X_test, y_train, y_test, cy_train, cy_test = train_test_split(\n",
    "    X, y, country_year, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 4. Train Random Forest (same pattern as economic code)\n",
    "# ===============================\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight=\"balanced\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate accuracy + ROC-AUC (print like your economic model)\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nâœ… Model Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "# ROC-AUC if probabilities available and both classes present in y_test\n",
    "if y_prob is not None and len(np.unique(y_test)) > 1:\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "        print(f\"âœ… ROC-AUC Score: {auc:.3f}\\n\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ===============================\n",
    "# 5. Predict for Next Year (simulate next year like economic code)\n",
    "# ===============================\n",
    "latest_year = data[\"Year\"].max()\n",
    "future_data = data[data[\"Year\"] == latest_year].copy()\n",
    "future_data[\"Year\"] = latest_year + 1  # simulate next year (predict for Year+1)\n",
    "\n",
    "# Build X_future by dropping same columns\n",
    "X_future = future_data.drop(columns=[c for c in drop_cols if c in future_data.columns], errors=\"ignore\")\n",
    "\n",
    "# If X_future empty -> nothing to predict\n",
    "if X_future.shape[0] == 0:\n",
    "    print(\"ðŸŒ No countries available for prediction (check latest year rows).\")\n",
    "else:\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        future_probs = model.predict_proba(X_future)[:, 1]\n",
    "    else:\n",
    "        future_probs = model.predict(X_future)  # fallback, 0/1\n",
    "\n",
    "    future_data[\"Crisis_Probability\"] = future_probs\n",
    "    # keep probability in [0,1]; if previously not, ensure scaling below if needed\n",
    "\n",
    "    # ===============================\n",
    "    # 6. Identify High-Risk Countries\n",
    "    # ===============================\n",
    "    threshold = 0.80  # show countries with â‰¥80% crisis probability\n",
    "    high_risk = future_data[future_data[\"Crisis_Probability\"] >= threshold]\n",
    "\n",
    "    if high_risk.empty:\n",
    "        print(\"ðŸŒ No countries exceed the crisis probability threshold.\")\n",
    "    else:\n",
    "        # SHAP explanation - compute shap on X_future, align with rows\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_future)  # may be list or array\n",
    "\n",
    "        # Select SHAP values for positive class (class 1) robustly\n",
    "        if isinstance(shap_values, list) and len(shap_values) > 1:\n",
    "            shap_pos = shap_values[1]\n",
    "        else:\n",
    "            shap_pos = shap_values\n",
    "\n",
    "        # shap_pos may sometimes be 3D depending on shap version; normalize to 2D (n_samples, n_features)\n",
    "        if hasattr(shap_pos, \"ndim\") and shap_pos.ndim == 3:\n",
    "            # common shape: (n_samples, n_features, n_classes) -> take class 1\n",
    "            shap_pos = shap_pos[:, :, 1]\n",
    "\n",
    "        # convert to DataFrame aligned with X_future index\n",
    "        shap_df = pd.DataFrame(shap_pos, columns=X_future.columns, index=X_future.index)\n",
    "\n",
    "        print(\"\\nðŸ”¥ High-Risk Countries (â‰¥80% Crisis Probability)\\n\")\n",
    "        for idx in high_risk.index:\n",
    "            country = high_risk.loc[idx, \"Country Name\"]\n",
    "            prob = high_risk.loc[idx, \"Crisis_Probability\"] * 100 if future_data[\"Crisis_Probability\"].max() <= 1 else high_risk.loc[idx, \"Crisis_Probability\"] * 100\n",
    "            # If probabilities are 0-1 -> multiply by 100, if they are already 0-100 you'd adjust; here we assume 0-1.\n",
    "\n",
    "            # Get SHAP row for this index (aligned)\n",
    "            if idx in shap_df.index:\n",
    "                instance_shap = shap_df.loc[idx].values\n",
    "            else:\n",
    "                # fallback: find by position\n",
    "                instance_shap = shap_df.iloc[list(high_risk.index).index(idx)].values\n",
    "\n",
    "            # Pair features with shap values and feature value (from X_future)\n",
    "            feature_contribs = sorted(\n",
    "                zip(X_future.columns, instance_shap, X_future.loc[idx].values),\n",
    "                key=lambda x: abs(x[1]),\n",
    "                reverse=True\n",
    "            )[:3]\n",
    "\n",
    "            print(f\"ðŸš¨ {country} â€” Crisis Probability: {prob:.2f}%\")\n",
    "            for feat, contrib, val in feature_contribs:\n",
    "                print(f\"   {feat:<45} Contribution: {contrib:+.3f} | Value: {val:.2f}\")\n",
    "            print(\"-\" * 70)\n",
    "\n",
    "    # Save predictions for the simulated next year\n",
    "    out_file = \"food_future_predictions.csv\"\n",
    "    future_data.to_csv(out_file, index=False)\n",
    "    print(f\"\\nðŸ“‚ Saved future-year predictions to: {out_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18557,
     "status": "ok",
     "timestamp": 1761670527986,
     "user": {
      "displayName": "Swaroop Tandle",
      "userId": "04403577212311715821"
     },
     "user_tz": -330
    },
    "id": "aAhvxRm-vjjD",
    "outputId": "087fc6ae-479a-45a9-fae1-69cbda9b517b"
   },
   "outputs": [],
   "source": [
    "# # food_ews_timeaware.py\n",
    "# # random forest model\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.metrics import (\n",
    "#     accuracy_score, precision_score, recall_score, f1_score,\n",
    "#     confusion_matrix, roc_auc_score, classification_report, average_precision_score\n",
    "# )\n",
    "# import shap\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# RANDOM_STATE = 42\n",
    "\n",
    "# # ------------------------\n",
    "# # Config / file paths\n",
    "# # ------------------------\n",
    "# INPUT_FILE = \"/content/food_crisis_dataset_labeled.csv\"  # <- change to your file\n",
    "# OUT_PRED_CSV = \"food_crisis_2025_predictions.csv\"\n",
    "# EVAL_FEATURE_YEAR = 2023   # features year used for evaluation (to predict EVAL_FEATURE_YEAR+1)\n",
    "# PREDICT_FROM_YEAR = 2024   # year whose features we will use to predict 2025\n",
    "# PROB_THRESHOLD = 0.70      # threshold for flagging high risk (0-1)\n",
    "\n",
    "# # ------------------------\n",
    "# # 1) Load data\n",
    "# # ------------------------\n",
    "# df = pd.read_csv(INPUT_FILE)\n",
    "# df = df.copy()\n",
    "# if \"Year\" not in df.columns:\n",
    "#     raise KeyError(\"Dataset must contain 'Year' column.\")\n",
    "# df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "\n",
    "# required_cols = [\"Country Name\", \"Year\", \"Crisis_Label\"]\n",
    "# if not all(c in df.columns for c in required_cols):\n",
    "#     raise KeyError(f\"Dataset must contain columns: {required_cols}\")\n",
    "\n",
    "# # Choose features (ensure names match your CSV)\n",
    "# features = [\n",
    "#     \"Cereal yield (kg per hectare)\",\n",
    "#     \"Food imports (% of merchandise imports)\",\n",
    "#     \"Food production index (2014-2016 = 100)\",\n",
    "#     \"GDP (current US$)\",\n",
    "#     \"GDP growth (annual %)\",\n",
    "#     \"GDP per capita (current US$)\",\n",
    "#     \"Inflation, consumer prices (annual %)\",\n",
    "#     \"Population growth (annual %)\"\n",
    "# ]\n",
    "\n",
    "# # Validate features present\n",
    "# missing_feats = [c for c in features if c not in df.columns]\n",
    "# if missing_feats:\n",
    "#     raise KeyError(f\"Missing feature columns in CSV: {missing_feats}\")\n",
    "\n",
    "# # ------------------------\n",
    "# # 2) Build forecasting target: Crisis at t+1\n",
    "# #    For each country, target = Crisis_Label shifted -1 (next year)\n",
    "# # ------------------------\n",
    "# df = df.sort_values([\"Country Name\", \"Year\"]).reset_index(drop=True)\n",
    "# df[\"Crisis_Target_t1\"] = df.groupby(\"Country Name\")[\"Crisis_Label\"].shift(-1)\n",
    "\n",
    "# # Drop rows where target is NaN (i.e., last year for each country)\n",
    "# df_model = df.dropna(subset=features + [\"Crisis_Target_t1\"]).copy()\n",
    "# df_model[\"Crisis_Target_t1\"] = df_model[\"Crisis_Target_t1\"].astype(int)\n",
    "\n",
    "# # ------------------------\n",
    "# # 3) Prepare evaluation split (time-aware)\n",
    "# #    Train on years <= EVAL_FEATURE_YEAR-1  (features up to 2022)\n",
    "# #    Test on rows where Year == EVAL_FEATURE_YEAR (features at 2023, target is 2024)\n",
    "# # ------------------------\n",
    "# train_cutoff = EVAL_FEATURE_YEAR - 1  # e.g., 2022\n",
    "# train_rows = df_model[df_model[\"Year\"] <= train_cutoff].copy()\n",
    "# test_rows = df_model[df_model[\"Year\"] == EVAL_FEATURE_YEAR].copy()  # features=2023 -> target=2024\n",
    "\n",
    "# if train_rows.empty or test_rows.empty:\n",
    "#     raise ValueError(f\"Not enough data for train/test with EVAL_FEATURE_YEAR={EVAL_FEATURE_YEAR}.\")\n",
    "\n",
    "# X_train = train_rows[features].values\n",
    "# y_train = train_rows[\"Crisis_Target_t1\"].values.astype(int)\n",
    "# X_test = test_rows[features].values\n",
    "# y_test = test_rows[\"Crisis_Target_t1\"].values.astype(int)\n",
    "\n",
    "# # Impute missing values (median)\n",
    "# imputer = SimpleImputer(strategy=\"median\")\n",
    "# X_train = imputer.fit_transform(X_train)\n",
    "# X_test = imputer.transform(X_test)\n",
    "\n",
    "# # ------------------------\n",
    "# # 4) Train model (Random Forest)\n",
    "# # ------------------------\n",
    "# model = RandomForestClassifier(\n",
    "#     n_estimators=300,\n",
    "#     random_state=RANDOM_STATE,\n",
    "#     class_weight=\"balanced_subsample\",\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # ------------------------\n",
    "# # 5) Evaluate on test (features=EVAL_FEATURE_YEAR predict EVAL_FEATURE_YEAR+1)\n",
    "# # ------------------------\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "# acc = accuracy_score(y_test, y_pred)\n",
    "# prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "# rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "# f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# roc_auc = roc_auc_score(y_test, y_prob) if y_prob is not None and len(np.unique(y_test)) > 1 else float(\"nan\")\n",
    "# pr_auc = average_precision_score(y_test, y_prob) if y_prob is not None and len(np.unique(y_test)) > 1 else float(\"nan\")\n",
    "\n",
    "# print(\"\\n=== Evaluation (simulating prediction of year\", EVAL_FEATURE_YEAR+1, \") ===\")\n",
    "# print(f\"Training years used (features -> target): {train_rows['Year'].min()}-{train_rows['Year'].max()} -> targets {train_rows['Year'].min()+1}-{train_rows['Year'].max()+1}\")\n",
    "# print(f\"Test year (features): {EVAL_FEATURE_YEAR} -> target year: {EVAL_FEATURE_YEAR+1}\\n\")\n",
    "\n",
    "# print(f\"Accuracy : {acc:.4f}\")\n",
    "# print(f\"Precision: {prec:.4f}\")\n",
    "# print(f\"Recall   : {rec:.4f}\")\n",
    "# print(f\"F1-score : {f1:.4f}\")\n",
    "# print(f\"ROC-AUC  : {roc_auc:.4f}\")\n",
    "# print(f\"PR-AUC   : {pr_auc:.4f}\")\n",
    "# print(\"\\nConfusion Matrix (rows=actual target, cols=predicted):\")\n",
    "# print(cm)\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# # ------------------------\n",
    "# # 6) Retrain on all available up to Year == EVAL_FEATURE_YEAR (i.e., use features through 2023 to learn targets through 2024)\n",
    "# #    Then use rows where Year == PREDICT_FROM_YEAR (2024) to predict 2025\n",
    "# # ------------------------\n",
    "# train_full_rows = df_model[df_model[\"Year\"] <= EVAL_FEATURE_YEAR].copy()  # rows with features <=2023 and targets up to 2024\n",
    "# X_full = train_full_rows[features].values\n",
    "# y_full = train_full_rows[\"Crisis_Target_t1\"].values.astype(int)\n",
    "# X_full = imputer.fit_transform(X_full)  # refit imputer on full training\n",
    "# model.fit(X_full, y_full)               # retrain on full\n",
    "\n",
    "# # Prepare 2024 features to predict 2025\n",
    "# predict_feat_rows = df[df[\"Year\"] == PREDICT_FROM_YEAR].copy()\n",
    "# if predict_feat_rows.empty:\n",
    "#     raise ValueError(f\"No rows found for Year == {PREDICT_FROM_YEAR} to use as features for predicting {PREDICT_FROM_YEAR+1}.\")\n",
    "\n",
    "# X_predict = predict_feat_rows[features].values\n",
    "# X_predict = imputer.transform(X_predict)\n",
    "# probs_2025 = model.predict_proba(X_predict)[:, 1]\n",
    "# predict_feat_rows = predict_feat_rows.reset_index(drop=True)\n",
    "# predict_feat_rows[\"Crisis_Probability_2025\"] = probs_2025\n",
    "# predict_feat_rows[\"Crisis_Pred_2025\"] = (predict_feat_rows[\"Crisis_Probability_2025\"] >= PROB_THRESHOLD).astype(int)\n",
    "\n",
    "# # ------------------------\n",
    "# # 7) SHAP explanations for the predicted rows (2025)\n",
    "# # ------------------------\n",
    "# explainer = shap.TreeExplainer(model)\n",
    "# shap_values_all = explainer.shap_values(X_predict)\n",
    "\n",
    "# # pick positive class shap values robustly\n",
    "# if isinstance(shap_values_all, list) and len(shap_values_all) > 1:\n",
    "#     shap_pos = shap_values_all[1]\n",
    "# else:\n",
    "#     shap_pos = shap_values_all\n",
    "\n",
    "# # ensure 2D: (n_samples, n_features)\n",
    "# if hasattr(shap_pos, \"ndim\") and shap_pos.ndim == 3:\n",
    "#     # some versions return shape (n_samples, n_features, n_classes)\n",
    "#     shap_pos = shap_pos[:, :, 1]\n",
    "\n",
    "# shap_df = pd.DataFrame(shap_pos, columns=features, index=predict_feat_rows.index)\n",
    "\n",
    "# # ------------------------\n",
    "# # 8) Display 2025 predictions and SHAP contributions\n",
    "# # ------------------------\n",
    "# print(f\"\\n=== 2025 Early-Warning Predictions (based on {PREDICT_FROM_YEAR} features) ===\")\n",
    "# # show top countries by probability\n",
    "# predict_feat_rows[\"Crisis_Probability_2025_pct\"] = predict_feat_rows[\"Crisis_Probability_2025\"] * 100\n",
    "# pred_sorted = predict_feat_rows.sort_values(\"Crisis_Probability_2025\", ascending=False)\n",
    "\n",
    "# # Print summary top N (all or filtered)\n",
    "# topN = 50\n",
    "# display_df = pred_sorted[[\"Country Name\", \"Country Code\", \"Crisis_Probability_2025\", \"Crisis_Pred_2025\"]].head(topN).copy()\n",
    "# display_df[\"Crisis_Probability_2025\"] = (display_df[\"Crisis_Probability_2025\"]*100).round(2)\n",
    "# print(display_df.to_string(index=False))\n",
    "\n",
    "# # Print high-risk countries with SHAP details\n",
    "# high_risk = predict_feat_rows[predict_feat_rows[\"Crisis_Probability_2025\"] >= PROB_THRESHOLD]\n",
    "# if high_risk.empty:\n",
    "#     print(f\"\\nNo countries exceed the threshold of {PROB_THRESHOLD:.2f} probability for 2025.\")\n",
    "# else:\n",
    "#     print(f\"\\nðŸ”¥ High-risk countries (prob >= {PROB_THRESHOLD:.2f}) with top 3 SHAP contributors:\\n\")\n",
    "#     for idx in high_risk.index:\n",
    "#         row = predict_feat_rows.loc[idx]\n",
    "#         country = row[\"Country Name\"]\n",
    "#         prob = row[\"Crisis_Probability_2025\"] * 100\n",
    "#         print(f\"ðŸš¨ {country} â€” Predicted Crisis Probability 2025: {prob:.2f}%\")\n",
    "#         # get SHAP for this index (shap_df index aligns with predict_feat_rows.reset_index)\n",
    "#         s = shap_df.loc[idx]\n",
    "#         top_feats = s.abs().sort_values(ascending=False).index[:3]\n",
    "#         for feat in top_feats:\n",
    "#             contrib = s[feat]\n",
    "#             val = row[feat]\n",
    "#             sign = \"+\" if contrib > 0 else \"-\"\n",
    "#             print(f\"   {feat:<50} Contribution: {contrib:+.4f} | Value: {val}\")\n",
    "#         print(\"-\"*80)\n",
    "\n",
    "# # ------------------------\n",
    "# # 9) Save predictions to CSV\n",
    "# # ------------------------\n",
    "# out_cols = [\"Country Name\", \"Country Code\", \"Year\"] + features + [\"Crisis_Probability_2025\", \"Crisis_Pred_2025\"]\n",
    "# predict_feat_rows[out_cols].to_csv(OUT_PRED_CSV, index=False)\n",
    "# print(f\"\\nâœ… 2025 predictions saved to: {OUT_PRED_CSV}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food_crisis_model.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'food_crisis_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPQSPDFDymCtu42rB3x/d3c",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
